{
  "$schema": "https://ui.shadcn.com/schema/registry-item.json",
  "name": "chat",
  "type": "registry:block",
  "title": "Chatbot",
  "description": "A chatbot component for AI applications",
  "dependencies": [
    "@llamaindex/chat-ui"
  ],
  "registryDependencies": [],
  "files": [
    {
      "path": "registry/chat/chat.tsx",
      "content": "'use client'\n\nimport {\n  ChatHandler,\n  ChatSection as ChatSectionUI,\n  Message,\n} from '@llamaindex/chat-ui'\n\nimport '@llamaindex/chat-ui/styles/markdown.css'\nimport '@llamaindex/chat-ui/styles/pdf.css'\nimport '@llamaindex/chat-ui/styles/editor.css'\nimport { useState } from 'react'\n\nconst initialMessages: Message[] = [\n  {\n    id: '1',\n    parts: [{ type: 'text', text: 'Write simple Javascript hello world code' }],\n    role: 'user',\n  },\n  {\n    id: '2',\n    role: 'assistant',\n    parts: [\n      {\n        type: 'text',\n        text: 'Got it! Here\\'s the simplest JavaScript code to print \"Hello, World!\" to the console:\\n\\n```javascript\\nconsole.log(\"Hello, World!\");\\n```\\n\\nYou can run this code in any JavaScript environment, such as a web browser\\'s console or a Node.js environment. Just paste the code and execute it to see the output.',\n      },\n    ],\n  },\n  {\n    id: '3',\n    parts: [{ type: 'text', text: 'Write a simple math equation' }],\n    role: 'user',\n  },\n  {\n    id: '4',\n    role: 'assistant',\n    parts: [\n      {\n        type: 'text',\n        text: \"Let's explore a simple mathematical equation using LaTeX:\\n\\n The quadratic formula is: $$x = \\\\frac{-b \\\\pm \\\\sqrt{b^2 - 4ac}}{2a}$$\\n\\nThis formula helps us solve quadratic equations in the form $ax^2 + bx + c = 0$. The solution gives us the x-values where the parabola intersects the x-axis.\",\n      },\n    ],\n  },\n]\n\nexport function ChatSection() {\n  // You can replace the handler with a useChat hook from Vercel AI SDK\n  const handler = useMockChat(initialMessages)\n  return (\n    <div className=\"flex max-h-[80vh] flex-col gap-6 overflow-y-auto\">\n      <ChatSectionUI handler={handler} />\n    </div>\n  )\n}\n\nfunction useMockChat(initMessages: Message[]): ChatHandler {\n  const [messages, setMessages] = useState<Message[]>(initMessages)\n  const [status, setStatus] = useState<\n    'streaming' | 'ready' | 'error' | 'submitted'\n  >('ready')\n\n  const append = async (message: Message) => {\n    const mockResponse: Message = {\n      id: '5',\n      role: 'assistant',\n      parts: [{ type: 'text', text: '' }],\n    }\n    setMessages(prev => [...prev, message, mockResponse])\n\n    const mockContent =\n      'This is a mock response. In a real implementation, this would be replaced with an actual AI response.'\n\n    let streamedContent = ''\n    const words = mockContent.split(' ')\n\n    for (const word of words) {\n      await new Promise(resolve => setTimeout(resolve, 100))\n      streamedContent += (streamedContent ? ' ' : '') + word\n      setMessages(prev => {\n        return [\n          ...prev.slice(0, -1),\n          {\n            id: '6',\n            role: 'assistant',\n            parts: [{ type: 'text', text: streamedContent }],\n          },\n        ]\n      })\n    }\n\n    return mockContent\n  }\n\n  return {\n    messages,\n    status,\n    sendMessage: async (message: Message) => {\n      setStatus('submitted')\n      await append(message)\n      setStatus('ready')\n    },\n  }\n}\n",
      "type": "registry:block"
    }
  ],
  "css": {
    "@source '../node_modules/@llamaindex/chat-ui/**/*.{ts,tsx}'": ""
  }
}